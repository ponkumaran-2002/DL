{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
      "0       35         170          85       97.0             0.9   \n",
      "1       20         175         110      110.0             0.7   \n",
      "2       45         155          65       86.0             0.9   \n",
      "3       45         165          80       94.0             0.8   \n",
      "4       20         165          60       81.0             1.5   \n",
      "...    ...         ...         ...        ...             ...   \n",
      "38979   40         165          60       80.0             0.4   \n",
      "38980   45         155          55       75.0             1.5   \n",
      "38981   40         170         105      124.0             0.6   \n",
      "38982   40         160          55       75.0             1.5   \n",
      "38983   55         175          60       81.1             1.0   \n",
      "\n",
      "       eyesight(right)  hearing(left)  hearing(right)  systolic  relaxation  \\\n",
      "0                  0.9              1               1       118          78   \n",
      "1                  0.9              1               1       119          79   \n",
      "2                  0.9              1               1       110          80   \n",
      "3                  0.7              1               1       158          88   \n",
      "4                  0.1              1               1       109          64   \n",
      "...                ...            ...             ...       ...         ...   \n",
      "38979              0.6              1               1       107          60   \n",
      "38980              1.2              1               1       126          72   \n",
      "38981              0.5              1               1       141          85   \n",
      "38982              1.5              1               1        95          69   \n",
      "38983              1.0              1               1       114          66   \n",
      "\n",
      "       ...  triglyceride  HDL  LDL  hemoglobin  Urine protein  \\\n",
      "0      ...           153   70  142        19.8              1   \n",
      "1      ...           128   71  114        15.9              1   \n",
      "2      ...           120   57  112        13.7              3   \n",
      "3      ...           366   46   91        16.9              1   \n",
      "4      ...           200   47   92        14.9              1   \n",
      "...    ...           ...  ...  ...         ...            ...   \n",
      "38979  ...            53   61   72        12.3              1   \n",
      "38980  ...           100   76  131        12.5              2   \n",
      "38981  ...           196   48  138        17.1              1   \n",
      "38982  ...            48   79  116        12.0              1   \n",
      "38983  ...            57   64  137        13.9              1   \n",
      "\n",
      "       serum creatinine   AST   ALT  Gtp  dental caries  \n",
      "0                   1.0    61   115  125              1  \n",
      "1                   1.1    19    25   30              1  \n",
      "2                   0.6  1090  1400  276              0  \n",
      "3                   0.9    32    36   36              0  \n",
      "4                   1.2    26    28   15              0  \n",
      "...                 ...   ...   ...  ...            ...  \n",
      "38979               0.5    18    18   21              1  \n",
      "38980               0.6    23    11   12              0  \n",
      "38981               0.8    24    23   35              1  \n",
      "38982               0.6    24    20   17              0  \n",
      "38983               1.0    18    12   16              0  \n",
      "\n",
      "[38984 rows x 22 columns]\n",
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "38979    0\n",
      "38980    0\n",
      "38981    1\n",
      "38982    1\n",
      "38983    1\n",
      "Name: smoking, Length: 38984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\ponku\\\\OneDrive\\\\Desktop\\\\Desktop\\\\Study\\\\sem-6\\\\Deep Learning\\\\Lab\\\\ex-1\\\\Dataset_Smoking\\\\train_dataset.csv\",encoding=\"UTF-8\")\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "torch.Size([31187, 22]) torch.Size([7797, 22]) torch.Size([31187]) torch.Size([7797])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, train_size=0.8, stratify=y, random_state=123)\n",
    "X_train = torch.tensor(X_train.values,dtype=torch.float32)\n",
    "X_test=torch.tensor(X_test.values,dtype=torch.float32)\n",
    "Y_train=torch.tensor(Y_train.values, dtype=torch.long)\n",
    "Y_test=torch.tensor(Y_test.values, dtype=torch.long)\n",
    "samples, features = X_train.shape\n",
    "classes = Y_test.unique()\n",
    "print(features)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.first_layer = nn.Linear(features, 5)\n",
    "        self.second_layer = nn.Linear(5, 10)\n",
    "        self.third_layer = nn.Linear(10, 15)\n",
    "        self.fourth_layer = nn.Linear(15, 20)\n",
    "        self.fifth_layer = nn.Linear(20, 25)\n",
    "        self.sixth_layer = nn.Linear(25, 30)\n",
    "        self.final_layer = nn.Linear(30,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        layer_out = self.relu(self.first_layer(X_batch))\n",
    "        layer_out = self.relu(self.second_layer(layer_out))\n",
    "        layer_out = self.relu(self.third_layer(layer_out))\n",
    "        layer_out = self.relu(self.fourth_layer(layer_out))\n",
    "        layer_out = self.relu(self.fifth_layer(layer_out))\n",
    "        layer_out = self.relu(self.sixth_layer(layer_out))\n",
    "        return self.sigmoid(self.final_layer(layer_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier()\n",
    "preds = classifier(X_train[:5])\n",
    "preds\n",
    "def TrainModel(model, loss_func, optimizer, X, Y, epochs=500):\n",
    "    for i in range(epochs):\n",
    "        preds = model(X) \n",
    "        loss = loss_func(preds, Y) \n",
    "        optimizer.zero_grad() \n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"NegLogLoss : {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n",
      "NegLogLoss : -0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "torch.manual_seed(42) ##For reproducibility.This will make sure that same random weights are initialized each time.\n",
    "epochs = 2000\n",
    "learning_rate = torch.tensor(1/1e3) # 0.01\n",
    "classifier = Classifier()\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = SGD(params=classifier.parameters(), lr=learning_rate)\n",
    "TrainModel(classifier, nll_loss, optimizer, X_train, Y_train, epochs=epochs)\n",
    "test_preds = classifier(X_test) \n",
    "test_preds = torch.argmax(test_preds, axis=1) \n",
    "train_preds = classifier(X_train)\n",
    "train_preds = torch.argmax(train_preds, axis=1)\n",
    "test_preds[:5], train_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.63\n",
      "Test  Accuracy : 0.63\n",
      "Test Data Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78      4933\n",
      "           1       0.00      0.00      0.00      2864\n",
      "\n",
      "    accuracy                           0.63      7797\n",
      "   macro avg       0.32      0.50      0.39      7797\n",
      "weighted avg       0.40      0.63      0.49      7797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ponku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ponku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ponku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(Y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(Y_test, test_preds)))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Test Data Classification Report : \")\n",
    "print(classification_report(Y_test, test_preds))\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights:  tensor([0.2000, 0.2000])\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def perceptron(inputs, weights):\n",
    "    weighted_sum = torch.dot(inputs, weights)\n",
    "    prediction = torch.where(weighted_sum > 0, torch.tensor(1.0), torch.tensor(-1.0))\n",
    "    return prediction\n",
    "\n",
    "def train_perceptron(inputs, targets, weights, learning_rate, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            prediction = perceptron(input_, weights)\n",
    "            error = targets[i] - prediction\n",
    "            weights += learning_rate * error * input_\n",
    "    return weights\n",
    "def calculate_accuracy(inputs, targets, weights):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            prediction = perceptron(input_, weights)\n",
    "            if prediction == targets[i]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total\n",
    "\n",
    "inputs = torch.tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]],dtype=torch.float32)\n",
    "targets = torch.tensor([-1, -1, -1, 1],dtype=torch.float32)\n",
    "weights = torch.zeros(2)\n",
    "learning_rate = 0.1\n",
    "epochs = 20\n",
    "\n",
    "trained_weights = train_perceptron(inputs, targets, weights, learning_rate, epochs)\n",
    "print(\"Trained Weights: \", trained_weights)\n",
    "accuracy = calculate_accuracy(inputs, targets, trained_weights)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd3822b8771159e12ad533e9b9e180a352f65546fe5f5bf6c3921988514f69c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
